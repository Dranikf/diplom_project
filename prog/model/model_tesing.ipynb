{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbadf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from nets_algo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c580b5",
   "metadata": {},
   "source": [
    "## Функция потерь\n",
    "\n",
    "Создание функции потерь в torch\n",
    "https://neptune.ai/blog/pytorch-loss-functions. Для задач бинарной классификации рекомендуют использовать CrossEntropy функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f72c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c282bd6",
   "metadata": {},
   "source": [
    "# Загрузка и подговтовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5487f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/dranik/KFA/university/proc_2.csv\", \n",
    "    index_col = 0\n",
    ")\n",
    "\n",
    "save_ind = data[data['Y'] == 0].sample(\n",
    "    sum(data['Y']), random_state = 0\n",
    ").index.union(data[data['Y'] == 1].index)\n",
    "data = data.loc[save_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a704ed",
   "metadata": {},
   "source": [
    "Нужно провести One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f6ab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13926, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array(data[['Y']])\n",
    "X = data.drop('Y', axis = 1)\n",
    "\n",
    "X = np.concatenate([\n",
    "    OneHotEncoder(sparse = False).\\\n",
    "    fit_transform(X.loc[:,X.dtypes == \"O\"]),\n",
    "    X.loc[:,X.dtypes != \"O\"].to_numpy()\n",
    "], axis = 1)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ab050",
   "metadata": {},
   "source": [
    "Разбивка на Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94cb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(\n",
    "        X,Y, random_state = 0, stratify = Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75f303",
   "metadata": {},
   "source": [
    "## Создание набора данных и загрузчика данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928ee7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = My_data_set(\n",
    "    torch.tensor(X_train.astype('float32')), \n",
    "    torch.tensor(y_train.astype('float32'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8179bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader =\\\n",
    "torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b8fa3",
   "metadata": {},
   "source": [
    "# Эксперименты с построителем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167bebf",
   "metadata": {},
   "source": [
    "Модель на которой планируется проводить тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3adb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    net = ResultNet(\n",
    "        [train_data_loader.dataset.X.shape[1], 5]\n",
    "    )\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        net.parameters(), \n",
    "        weight_decay = 0.5,\n",
    "        lr = 0.1\n",
    "    )\n",
    "    \n",
    "    return [net, optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96c975",
   "metadata": {},
   "source": [
    "Базовый построитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3976d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_basic(\n",
    "    model, optimizer, loss_fn, \n",
    "    train_loader, epochs=20\n",
    "):\n",
    "    '''Алгоритм обучения сети'''\n",
    "    # inputs:\n",
    "    # model - модель которая подлежит обучению\n",
    "    # optimizer - оптимизатор, который педполагается использовать\n",
    "    # loss_fn - функция потерь\n",
    "    # train_loader - загрузчик обучающих данных\n",
    "    # epochs - эпохи используемые в нейронной сети\n",
    "    # lr_decr - степень понижения параметра learning rate\n",
    "    \n",
    "    initial_loss = get_loss_value(\n",
    "        loss_fn, model, train_loader\n",
    "    )\n",
    "    \n",
    "    fun_arr = []\n",
    "    fun_arr.append(initial_loss)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # для отслеживания процесса\n",
    "        # обучения буду сохранять текущее\n",
    "        # значение целевой функии\n",
    "        fun_arr.append(get_loss_value(\n",
    "            loss_fn, model, train_loader\n",
    "        ))\n",
    "\n",
    "    \n",
    "    return fun_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c451ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.521753311157227, 21.808807373046875, 10.963159561157227, 7.656264305114746]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, optimizer = create_model()\n",
    "\n",
    "train_basic(\n",
    "    net, optimizer, loss_fn, \n",
    "    train_data_loader, epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f40b10",
   "metadata": {},
   "source": [
    "Улучшенный построитель с возможностью торможения learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f7b4104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.521753311157227, 21.808807373046875, 10.963159561157227, 7.656264305114746]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, optimizer = create_model()\n",
    "\n",
    "train_basic(\n",
    "    net, optimizer, loss_fn, \n",
    "    train_data_loader, epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812ed2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, optimizer, loss_fn, \n",
    "    train_loader, epochs=20, \n",
    "    lr_scheduler = None\n",
    "):\n",
    "    '''Алгоритм обучения сети'''\n",
    "    # inputs:\n",
    "    # model - модель которая подлежит обучению\n",
    "    # optimizer - оптимизатор, который педполагается использовать\n",
    "    # loss_fn - функция потерь\n",
    "    # train_loader - загрузчик обучающих данных\n",
    "    # epochs - эпохи используемые в нейронной сети\n",
    "    # lr_scheduler - планировщик learning rate\n",
    "    \n",
    "    initial_loss = get_loss_value(\n",
    "        loss_fn, model, train_loader\n",
    "    )\n",
    "    \n",
    "    fun_arr = []\n",
    "    fun_arr.append(initial_loss)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "        # для отслеживания процесса\n",
    "        # обучения буду сохранять текущее\n",
    "        # значение целевой функии\n",
    "        fun_arr.append(get_loss_value(\n",
    "            loss_fn, model, train_loader\n",
    "        ))\n",
    "\n",
    "    \n",
    "    return fun_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b44c4c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.521753311157227, 21.808807373046875, 20.100093841552734, 19.85100555419922]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, optimizer = create_model()\n",
    "my_lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer, gamma = 0.1\n",
    ")\n",
    "\n",
    "train(\n",
    "    net, optimizer, loss_fn, \n",
    "    train_data_loader, epochs = 3,\n",
    "    lr_scheduler = my_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d527848",
   "metadata": {},
   "source": [
    "# Массовое построение моделей заданной формы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5180f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_get_perfomance(\n",
    "    hidden_layers_ranges, epochs, loss_fn,\n",
    "    train_loader, X_test, y_test, weight_decay = 0.5, \n",
    "    lr = 0.1\n",
    "):\n",
    "    '''Метод обеспечивает построение моделей заданных форм\n",
    "    и \"снимает\" инофрмацию о их свойсвах'''\n",
    "    # inputs:\n",
    "    # hidden_layers_ranges - инофрмация о внутренних\n",
    "    #                        слоях модели как list\n",
    "    #                        который содержит также списки\n",
    "    #                        типа [<нейноны 1 слоя>, <нейноны 2 слоя>, ...]\n",
    "    # lr -                   learning rate с которого начинается\n",
    "    #                        оптимизация\n",
    "    # epochs -               сколько эпох проходит каждая из \n",
    "    #                        форм модели\n",
    "    # test_X, test_y -       данные на которых проводиться валидация\n",
    "    #                        модели\n",
    "    # train_loader -         загрузчик трерировочных данных\n",
    "    # weight_decay -         параметр регуляризации\n",
    "    # output:\n",
    "    # [learning_info, auc_info, nets]\n",
    "    # learning_info -        pandas.DataFrame по столбцам значения целевой\n",
    "    #                        функции для эпохи в строке\n",
    "    # auc_info -             pandas.Series AUC на тестовых данных для\n",
    "    #                        каждой формы модели\n",
    "    # nets -                 список с полученными моделями - с перспективой\n",
    "    #                        дообучения\n",
    "    \n",
    "    \n",
    "    # выходные массивы\n",
    "    learning_info = pd.DataFrame()\n",
    "    auc_info = pd.Series(dtype = 'float64')\n",
    "    nets = []\n",
    "    \n",
    "    \n",
    "    for layers_info in hidden_layers_ranges:\n",
    "        # применение текущих настроек =================\n",
    "        net = ResultNet(\n",
    "            [train_loader.dataset.X.shape[1]] + \n",
    "            layers_info\n",
    "        )\n",
    "        optimizer = optim.Adam(\n",
    "            net.parameters(), \n",
    "            weight_decay = weight_decay, \n",
    "            lr = lr\n",
    "        )\n",
    "        # применение текущих настроек =================\n",
    "        # обучение ====================================\n",
    "        #print(net.layers[0].bias)\n",
    "        lc = train(\n",
    "            net, optimizer, loss_fn, \n",
    "            train_loader, epochs = epochs\n",
    "        )\n",
    "        # обучение ====================================\n",
    "        # снятие метрик ===============================\n",
    "        probs_hat = net(\n",
    "            torch.tensor(X_test.astype('float32'))\n",
    "        ).detach().numpy()\n",
    "    \n",
    "        auc = roc_auc_score(y_test, probs_hat)\n",
    "        # снятие метрик ===============================\n",
    "        # сохранение информации =======================\n",
    "        \n",
    "        identyfyer = str(layers_info)\n",
    "        learning_info.loc[:, identyfyer] = lc\n",
    "        auc_info[identyfyer] = auc\n",
    "        nets.append(net)\n",
    "        \n",
    "        # сохранение информации =======================\n",
    "        print(identyfyer + \" AUC = \" + str(auc))\n",
    "        \n",
    "    return [learning_info, auc_info, nets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2a19c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] AUC = 0.4916189966549887\n",
      "[3, 3] AUC = 0.58868667646955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[         [4]     [3, 3]\n",
       " 0  40.220894  26.253555\n",
       " 1  10.559843   6.866017\n",
       " 2   7.039437   3.470518\n",
       " 3   5.462039   0.694448\n",
       " 4   3.094617   0.693317\n",
       " 5   3.012087   0.695041,\n",
       " [4]       0.491619\n",
       " [3, 3]    0.588687\n",
       " dtype: float64,\n",
       " [ResultNet(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=108, out_features=4, bias=True)\n",
       "      (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  ResultNet(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=108, out_features=3, bias=True)\n",
       "      (1): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (2): Linear(in_features=3, out_features=1, bias=True)\n",
       "    )\n",
       "  )]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit_get_perfomance(\n",
    "    [[4], [3,3]], 5, loss_fn,\n",
    "    train_data_loader, X_test, y_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

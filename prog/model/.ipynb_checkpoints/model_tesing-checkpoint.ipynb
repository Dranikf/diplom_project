{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbadf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from nets_algo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c580b5",
   "metadata": {},
   "source": [
    "## Функция потерь\n",
    "\n",
    "Создание функции потерь в torch\n",
    "https://neptune.ai/blog/pytorch-loss-functions. Для задач бинарной классификации рекомендуют использовать CrossEntropy функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f72c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c282bd6",
   "metadata": {},
   "source": [
    "# Загрузка и подговтовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5487f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/dranik/KFA/university/proc_2.csv\", \n",
    "    index_col = 0\n",
    ")\n",
    "\n",
    "save_ind = data[data['Y'] == 0].sample(\n",
    "    sum(data['Y']), random_state = 0\n",
    ").index.union(data[data['Y'] == 1].index)\n",
    "data = data.loc[save_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a704ed",
   "metadata": {},
   "source": [
    "Нужно провести One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f6ab70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13926, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array(data[['Y']])\n",
    "X = data.drop('Y', axis = 1)\n",
    "\n",
    "X = np.concatenate([\n",
    "    OneHotEncoder(sparse = False).\\\n",
    "    fit_transform(X.loc[:,X.dtypes == \"O\"]),\n",
    "    X.loc[:,X.dtypes != \"O\"].to_numpy()\n",
    "], axis = 1)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ab050",
   "metadata": {},
   "source": [
    "Разбивка на Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94cb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(\n",
    "        X,Y, random_state = 0, stratify = Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75f303",
   "metadata": {},
   "source": [
    "## Создание набора данных и загрузчика данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928ee7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = My_data_set(\n",
    "    torch.tensor(X_train.astype('float32')), \n",
    "    torch.tensor(y_train.astype('float32'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8179bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader =\\\n",
    "torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b680df",
   "metadata": {},
   "source": [
    "# Эксперименты с построителем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81731134",
   "metadata": {},
   "source": [
    "Модель на которой планируется проводить тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d660c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    net = ResultNet(\n",
    "        [train_data_loader.dataset.X.shape[1], 5]\n",
    "    )\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        net.parameters(), \n",
    "        weight_decay = 0.5,\n",
    "        lr = 0.1\n",
    "    )\n",
    "    \n",
    "    return [net, optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe06feb1",
   "metadata": {},
   "source": [
    "Базовый построитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18d32ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_basic(\n",
    "    model, optimizer, loss_fn, \n",
    "    train_loader, epochs=20\n",
    "):\n",
    "    '''Алгоритм обучения сети'''\n",
    "    # inputs:\n",
    "    # model - модель которая подлежит обучению\n",
    "    # optimizer - оптимизатор, который педполагается использовать\n",
    "    # loss_fn - функция потерь\n",
    "    # train_loader - загрузчик обучающих данных\n",
    "    # epochs - эпохи используемые в нейронной сети\n",
    "    # lr_decr - степень понижения параметра learning rate\n",
    "    \n",
    "    initial_loss = get_loss_value(\n",
    "        loss_fn, model, train_loader\n",
    "    )\n",
    "    \n",
    "    fun_arr = []\n",
    "    fun_arr.append(initial_loss)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # для отслеживания процесса\n",
    "        # обучения буду сохранять текущее\n",
    "        # значение целевой функии\n",
    "        fun_arr.append(get_loss_value(\n",
    "            loss_fn, model, train_loader\n",
    "        ))\n",
    "\n",
    "    \n",
    "    return fun_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbc9c5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.521753311157227, 21.808807373046875, 10.963159561157227, 7.656264305114746]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, optimizer = create_model()\n",
    "\n",
    "train_basic(\n",
    "    net, optimizer, loss_fn, \n",
    "    train_data_loader, epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0abbe",
   "metadata": {},
   "source": [
    "Улучшенный построитель с возможностью торможения learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_basic(\n",
    "    model, optimizer, loss_fn, \n",
    "    train_loader, epochs=20\n",
    "):\n",
    "    '''Алгоритм обучения сети'''\n",
    "    # inputs:\n",
    "    # model - модель которая подлежит обучению\n",
    "    # optimizer - оптимизатор, который педполагается использовать\n",
    "    # loss_fn - функция потерь\n",
    "    # train_loader - загрузчик обучающих данных\n",
    "    # epochs - эпохи используемые в нейронной сети\n",
    "    # lr_decr - степень понижения параметра learning rate\n",
    "    \n",
    "    initial_loss = get_loss_value(\n",
    "        loss_fn, model, train_loader\n",
    "    )\n",
    "    \n",
    "    fun_arr = []\n",
    "    fun_arr.append(initial_loss)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # для отслеживания процесса\n",
    "        # обучения буду сохранять текущее\n",
    "        # значение целевой функии\n",
    "        fun_arr.append(get_loss_value(\n",
    "            loss_fn, model, train_loader\n",
    "        ))\n",
    "\n",
    "    \n",
    "    return fun_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f2a2fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.521753311157227, 21.808807373046875, 10.963159561157227, 7.656264305114746]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, optimizer = create_model()\n",
    "\n",
    "train_basic(\n",
    "    net, optimizer, loss_fn, \n",
    "    train_data_loader, epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a11e00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, optimizer, loss_fn, \n",
    "    train_loader, epochs=20, lr_sheduler = None\n",
    "):\n",
    "    '''Алгоритм обучения сети'''\n",
    "    # inputs:\n",
    "    # model - модель которая подлежит обучению\n",
    "    # optimizer - оптимизатор, который педполагается использовать\n",
    "    # loss_fn - функция потерь\n",
    "    # train_loader - загрузчик обучающих данных\n",
    "    # epochs - эпохи используемые в нейронной сети\n",
    "    # lr_decr - степень понижения параметра learning rate\n",
    "    \n",
    "    initial_loss = get_loss_value(\n",
    "        loss_fn, model, train_loader\n",
    "    )\n",
    "    \n",
    "    fun_arr = []\n",
    "    fun_arr.append(initial_loss)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if lr_sheduler:\n",
    "            lr_sheduler.step()\n",
    "            \n",
    "        # для отслеживания процесса\n",
    "        # обучения буду сохранять текущее\n",
    "        # значение целевой функии\n",
    "        fun_arr.append(get_loss_value(\n",
    "            loss_fn, model, train_loader\n",
    "        ))\n",
    "\n",
    "    \n",
    "    return fun_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1409e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.521753311157227, 21.808807373046875, 10.963159561157227, 7.656264305114746]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, optimizer = create_model()\n",
    "optim.lr_sheduler.ExponentialLR(\n",
    "    optimizer, gamma = 0.1\n",
    ")\n",
    "\n",
    "train(\n",
    "    net, optimizer, loss_fn, \n",
    "    train_data_loader, epochs = 3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
